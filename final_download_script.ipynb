{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2fc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n",
      "SWOT_L4_HR_DAWG_SOS_DISCHARGE_V3\n",
      "Granules found: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded_files\\sos_europe\\eu_sword_v16_SOS_results_unconstrained_20230502T204408_20250502T204408_20251219T163700.nc\n",
      "GeoJSON reaches: 842\n",
      "Wrote 559 CSVs to: C:\\UNESCO\\Code\\data\\Dnipro_consensus_q_csvs\n",
      "Skipped 283 reaches not found in NetCDF. Example(s): [22601000045, 22511100015, 22511100041, 22511300291, 22511300281, 22511300301, 22511300063, 22511300051, 22511300084, 22511300093]\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "earthaccess.login(strategy=\"netrc\")\n",
    "print(\"Authenticated\")\n",
    "\n",
    "datasets = earthaccess.search_datasets(\n",
    "    keyword=\"SWOT L4 discharge\",\n",
    "    count=50\n",
    ")\n",
    "\n",
    "for d in datasets:\n",
    "    print(d[\"umm\"][\"ShortName\"])\n",
    "\n",
    "    SHORT_NAME = \"SWOT_L4_HR_DAWG_SOS_DISCHARGE_V3\"\n",
    "\n",
    "granules = earthaccess.search_data(\n",
    "    short_name=SHORT_NAME,\n",
    "    sort_key=\"-start_date\",\n",
    "    count=1\n",
    ")\n",
    "\n",
    "print(\"Granules found:\", len(granules))\n",
    "\n",
    "granules = earthaccess.search_data(\n",
    "    short_name=SHORT_NAME,\n",
    "    count=50  # enough to list all regions\n",
    ")\n",
    "\n",
    "eu_granules = [\n",
    "    g for g in granules\n",
    "    if g[\"meta\"][\"native-id\"].startswith(\"eu_\")\n",
    "]\n",
    "\n",
    "paths = earthaccess.download(\n",
    "    eu_granules,\n",
    "    local_path=\"./downloaded_files/sos_europe\"\n",
    ")\n",
    "\n",
    "paths\n",
    "\n",
    "print(paths[0])\n",
    "\n",
    "# -------------------------\n",
    "# paths\n",
    "# -------------------------\n",
    "NC_PATH = r\"downloaded_files\\sos_europe\\eu_sword_v16_SOS_results_unconstrained_20230502T204408_20250502T204408_20251219T163700.nc\"\n",
    "GEOJSON_PATH = r\"C:\\UNESCO\\Code\\data\\Dnipro_basin_shapefiles\\derived\\dnipro_sword_reaches_clip.geojson\"\n",
    "\n",
    "OUT_DIR = r\"C:\\UNESCO\\Code\\data\\Dnipro_consensus_q_csvs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# read reach_ids from geojson\n",
    "# -------------------------\n",
    "gdf = gpd.read_file(GEOJSON_PATH)\n",
    "\n",
    "# Try common field names; adjust if yours differs\n",
    "reach_field_candidates = [\"reach_id\", \"ReachID\", \"REACH_ID\", \"sword_reach_id\", \"SWORD_REACH_ID\"]\n",
    "reach_field = next((c for c in reach_field_candidates if c in gdf.columns), None)\n",
    "if reach_field is None:\n",
    "    raise ValueError(f\"Could not find a reach id field in GeoJSON. Columns: {list(gdf.columns)}\")\n",
    "\n",
    "dnipro_reach_ids = (\n",
    "    pd.to_numeric(gdf[reach_field], errors=\"coerce\")\n",
    "      .dropna()\n",
    "      .astype(\"int64\")\n",
    "      .unique()\n",
    ")\n",
    "\n",
    "print(f\"GeoJSON reaches: {len(dnipro_reach_ids)}\")\n",
    "\n",
    "# -------------------------\n",
    "# open netcdf + prep indexing\n",
    "# -------------------------\n",
    "ds = nc.Dataset(NC_PATH, \"r\")\n",
    "reaches = ds.groups[\"reaches\"]\n",
    "consensus = ds.groups[\"consensus\"]\n",
    "\n",
    "nc_reach_ids = reaches.variables[\"reach_id\"][:].astype(\"int64\")\n",
    "\n",
    "# map reach_id -> index in netcdf (fast lookup)\n",
    "id_to_idx = {int(rid): int(i) for i, rid in enumerate(nc_reach_ids)}\n",
    "\n",
    "# locate fill/missing for consensus_q\n",
    "qvar = consensus.variables[\"consensus_q\"]\n",
    "missing = None\n",
    "if \"_FillValue\" in qvar.ncattrs():\n",
    "    missing = qvar.getncattr(\"_FillValue\")\n",
    "elif \"missing_value\" in qvar.ncattrs():\n",
    "    missing = qvar.getncattr(\"missing_value\")\n",
    "\n",
    "time_var = consensus.variables[\"time_int\"]\n",
    "\n",
    "# -------------------------\n",
    "# export per reach\n",
    "# -------------------------\n",
    "skipped_not_found = []\n",
    "written = 0\n",
    "\n",
    "for rid in dnipro_reach_ids:\n",
    "    rid_int = int(rid)\n",
    "    if rid_int not in id_to_idx:\n",
    "        skipped_not_found.append(rid_int)\n",
    "        continue\n",
    "\n",
    "    i = id_to_idx[rid_int]\n",
    "\n",
    "    # vlen time array for this reach\n",
    "    times = np.asarray(time_var[i], dtype=\"float64\")\n",
    "    valid_time = times > -9.0e10\n",
    "    times_valid = times[valid_time].astype(\"int64\")\n",
    "\n",
    "    if times_valid.size == 0:\n",
    "        # still write an empty CSV with headers\n",
    "        df = pd.DataFrame({\"reach_id\": [], \"date\": [], \"consensus_q\": []})\n",
    "    else:\n",
    "        dates = np.array([\n",
    "            np.datetime64(\"2000-01-01\") + np.timedelta64(int(t), \"s\")\n",
    "            for t in times_valid\n",
    "        ])\n",
    "\n",
    "        # vlen discharge array for this reach\n",
    "        q = np.asarray(qvar[i], dtype=\"float64\")[valid_time]\n",
    "\n",
    "        if missing is not None:\n",
    "            q[q == missing] = np.nan\n",
    "        q[q <= -9.0e10] = np.nan\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"reach_id\": rid_int,\n",
    "            \"date\": dates.astype(\"datetime64[ns]\"),\n",
    "            \"consensus_q\": q\n",
    "        })\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, f\"reach_{rid_int}_consensus_q.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    written += 1\n",
    "\n",
    "ds.close()\n",
    "\n",
    "print(f\"Wrote {written} CSVs to: {OUT_DIR}\")\n",
    "if skipped_not_found:\n",
    "    print(f\"Skipped {len(skipped_not_found)} reaches not found in NetCDF. Example(s): {skipped_not_found[:10]}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
